{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tflearn\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DIR = 'test'\n",
    "TRAIN_DIR = 'train'\n",
    "IMG_SIZE = 8\n",
    "LR = 1e-3\n",
    "MODEL_NAME = 'odr-{}-{}.model'.format(LR, '6conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = int(img.split('.')[0])\n",
    "    one_hot_array = [0 for i in range(10)]\n",
    "    one_hot_array[word_label] = 1\n",
    "    return one_hot_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR, img)\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        training_data.append([np.array(img), np.array(label)])\n",
    "    \n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for num, img in enumerate(tqdm(os.listdir(TEST_DIR))):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img =cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        testing_data.append([np.array(img), num])\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 186.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()\n",
    "# if trained data is already present then\n",
    "# train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\My Arena\\PythonCodes\\Deep Learning with Neural Networks\\3-Optical_Digit_Recognizer\\odr-0.001-6conv-basic.model\n",
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"{}.meta\".format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print (\"Model Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train_data\n",
    "test = train_data\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 139  | total loss: 0.06832 | time: 0.051s\n",
      "| Adam | epoch: 025 | loss: 0.06832 - acc: 0.9945 -- iter: 64/90\n",
      "Training Step: 140  | total loss: 0.06172 | time: 1.071s\n",
      "| Adam | epoch: 025 | loss: 0.06172 - acc: 0.9951 | val_loss: 0.00191 - val_acc: 1.0000 -- iter: 90/90\n",
      "--\n",
      "INFO:tensorflow:E:\\My Arena\\PythonCodes\\Deep Learning with Neural Networks\\3-Optical_Digit_Recognizer\\odr-0.001-6conv-basic.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=25, validation_set=({'input': test_x}, {'targets': test_y}),snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 365.61it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAD7CAYAAADEpDe3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1eccfc2ae80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = process_test_data()\n",
    "#test_data = np.load('test_data.npy')\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "initial = random.randrange(0,50,1)\n",
    "\n",
    "# Now let's plot the images with the predicted tags for 12 pics\n",
    "for num, data in enumerate(test_data[initial:initial+12]):\n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "\n",
    "    y = fig.add_subplot(3, 4 , num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE, 1)\n",
    "    model_out = model.predict([data])[0]\n",
    "\n",
    "    str_label = model_out.index(max(model_out))\n",
    "    \n",
    "    y.imshow(orig, cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testing_accuracy():\n",
    "    correct = 0\n",
    "    total = len(os.listdir(TRAIN_DIR))\n",
    "    \n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        name = img.split('.')[0]\n",
    "        model_out = model.predict(np.array(cv2.imread(os.path.join(TRAIN_DIR,img), cv2.IMREAD_GRAYSCALE)).reshape(-1,IMG_SIZE, IMG_SIZE, 1))[0]\n",
    "        str_label = model_out.index(max(model_out))\n",
    "                                  \n",
    "        #print (name, str_label)\n",
    "        if str(name) == str(str_label):\n",
    "            correct += 1\n",
    "    \n",
    "    print (\"accuracy =\", (correct/total)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:00<00:00, 512.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 100.0\n"
     ]
    }
   ],
   "source": [
    "testing_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
